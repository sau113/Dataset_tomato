{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sau113/Dataset_tomato/blob/master/Trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QP_QrGqaNdzg",
        "colab_type": "code",
        "outputId": "035fa3dd-5aac-4e94-9083-b379f9fe9be9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1985
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "network = Sequential()\n",
        "\n",
        "network.add(Convolution2D(64,(3,3),input_shape = (64,64,3),activation = 'relu'))\n",
        "\n",
        "network.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "network.add(Convolution2D(128, (3, 3), activation = 'relu'))\n",
        "network.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "network.add(Convolution2D(256, (3, 3), activation = 'relu'))\n",
        "network.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "network.add(Convolution2D(512, (3, 3), activation = 'relu'))\n",
        "network.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "network.add(Flatten())\n",
        "\n",
        "network.add(Dense(output_dim = 1024, activation = 'relu'))\n",
        "network.add(Dense(output_dim = 1024, activation = 'relu'))\n",
        "network.add(Dense(output_dim = 6, activation = 'softmax'))\n",
        "\n",
        "network.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data = ImageDataGenerator(rescale = 1./255, \n",
        "                                shear_range = 0.2,\n",
        "                                zoom_range = 0.2,\n",
        "                                horizontal_flip = True)\n",
        "\n",
        "valid_data = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "\n",
        "\n",
        "! git clone https://github.com/sau113/Dataset_tomato.git\n",
        "\n",
        "\n",
        "  \n",
        "training_set = train_data.flow_from_directory('Dataset_tomato/Training_set',\n",
        "                                              target_size = (64,64),\n",
        "                                              batch_size = 10,\n",
        "                                              class_mode = \"categorical\")\n",
        "\n",
        "imgs, labels = next(training_set)\n",
        "\n",
        "print(labels[:,:])\n",
        "\n",
        "valid_set= valid_data.flow_from_directory('Dataset_tomato/Validation_set',\n",
        "                                          target_size = (64,64),\n",
        "                                          batch_size=10,\n",
        "                                          class_mode=\"categorical\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "network.fit_generator(training_set,\n",
        "                      steps_per_epoch = (5520+800)/10,\n",
        "                      epochs = 25 ,\n",
        "                      validation_data = valid_set,\n",
        "                      validation_steps = (4920+200)/10)\n",
        "\n",
        "\n",
        "\n",
        "network.save('train_data.h5')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=1024)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=1024)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=6)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Dataset_tomato'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)   \u001b[K\rremote: Counting objects:  66% (2/3)   \u001b[K\rremote: Counting objects: 100% (3/3)   \u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 11590 (delta 0), reused 2 (delta 0), pack-reused 11587\u001b[K\n",
            "Receiving objects: 100% (11590/11590), 299.66 MiB | 29.65 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n",
            "Checking out files: 100% (11451/11451), done.\n",
            "Found 6317 images belonging to 6 classes.\n",
            "[[1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]]\n",
            "Found 5117 images belonging to 6 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/25\n",
            "632/632 [==============================] - 57s 90ms/step - loss: 1.0664 - acc: 0.5991 - val_loss: 0.6649 - val_acc: 0.7712\n",
            "Epoch 2/25\n",
            "632/632 [==============================] - 51s 80ms/step - loss: 0.7624 - acc: 0.7214 - val_loss: 0.7870 - val_acc: 0.7647\n",
            "Epoch 3/25\n",
            "632/632 [==============================] - 51s 81ms/step - loss: 0.6105 - acc: 0.7853 - val_loss: 0.8011 - val_acc: 0.7422\n",
            "Epoch 4/25\n",
            "632/632 [==============================] - 53s 84ms/step - loss: 0.4907 - acc: 0.8284 - val_loss: 0.4966 - val_acc: 0.8259\n",
            "Epoch 5/25\n",
            "632/632 [==============================] - 47s 75ms/step - loss: 0.4396 - acc: 0.8436 - val_loss: 0.3559 - val_acc: 0.8689\n",
            "Epoch 6/25\n",
            "632/632 [==============================] - 44s 69ms/step - loss: 0.3624 - acc: 0.8696 - val_loss: 0.4528 - val_acc: 0.8468\n",
            "Epoch 7/25\n",
            "632/632 [==============================] - 47s 75ms/step - loss: 0.3199 - acc: 0.8898 - val_loss: 0.2648 - val_acc: 0.9037\n",
            "Epoch 8/25\n",
            "632/632 [==============================] - 51s 80ms/step - loss: 0.2867 - acc: 0.8926 - val_loss: 0.2863 - val_acc: 0.8966\n",
            "Epoch 9/25\n",
            "632/632 [==============================] - 50s 79ms/step - loss: 0.2616 - acc: 0.9081 - val_loss: 0.3444 - val_acc: 0.8845\n",
            "Epoch 10/25\n",
            "632/632 [==============================] - 51s 80ms/step - loss: 0.2412 - acc: 0.9139 - val_loss: 0.2970 - val_acc: 0.8992\n",
            "Epoch 11/25\n",
            "632/632 [==============================] - 50s 79ms/step - loss: 0.2231 - acc: 0.9181 - val_loss: 0.2781 - val_acc: 0.9109\n",
            "Epoch 12/25\n",
            "632/632 [==============================] - 50s 80ms/step - loss: 0.2046 - acc: 0.9275 - val_loss: 0.3182 - val_acc: 0.8923\n",
            "Epoch 13/25\n",
            "632/632 [==============================] - 50s 80ms/step - loss: 0.1942 - acc: 0.9305 - val_loss: 0.1626 - val_acc: 0.9394\n",
            "Epoch 14/25\n",
            "632/632 [==============================] - 50s 80ms/step - loss: 0.2073 - acc: 0.9301 - val_loss: 0.2226 - val_acc: 0.9273\n",
            "Epoch 15/25\n",
            "632/632 [==============================] - 50s 80ms/step - loss: 0.1710 - acc: 0.9407 - val_loss: 0.2712 - val_acc: 0.9252\n",
            "Epoch 16/25\n",
            "632/632 [==============================] - 50s 80ms/step - loss: 0.1730 - acc: 0.9380 - val_loss: 0.1873 - val_acc: 0.9341\n",
            "Epoch 17/25\n",
            "632/632 [==============================] - 51s 80ms/step - loss: 0.1600 - acc: 0.9478 - val_loss: 0.5440 - val_acc: 0.8525\n",
            "Epoch 18/25\n",
            "632/632 [==============================] - 51s 80ms/step - loss: 0.1449 - acc: 0.9524 - val_loss: 0.2382 - val_acc: 0.9271\n",
            "Epoch 19/25\n",
            "632/632 [==============================] - 50s 80ms/step - loss: 0.1536 - acc: 0.9487 - val_loss: 0.3305 - val_acc: 0.9136\n",
            "Epoch 20/25\n",
            "632/632 [==============================] - 51s 80ms/step - loss: 0.1258 - acc: 0.9559 - val_loss: 0.1540 - val_acc: 0.9457\n",
            "Epoch 21/25\n",
            "632/632 [==============================] - 51s 80ms/step - loss: 0.1430 - acc: 0.9483 - val_loss: 0.1731 - val_acc: 0.9357\n",
            "Epoch 22/25\n",
            "632/632 [==============================] - 51s 80ms/step - loss: 0.1383 - acc: 0.9532 - val_loss: 0.1545 - val_acc: 0.9476\n",
            "Epoch 23/25\n",
            "632/632 [==============================] - 51s 81ms/step - loss: 0.1182 - acc: 0.9594 - val_loss: 0.4524 - val_acc: 0.8958\n",
            "Epoch 24/25\n",
            "632/632 [==============================] - 51s 81ms/step - loss: 0.1086 - acc: 0.9641 - val_loss: 0.1739 - val_acc: 0.9482\n",
            "Epoch 25/25\n",
            "632/632 [==============================] - 51s 81ms/step - loss: 0.1795 - acc: 0.9485 - val_loss: 0.2935 - val_acc: 0.9150\n",
            "/content/Dataset_tomato\n",
            " Tester2.ipynb\t train_data.h5\t        Trainer.ipynb\n",
            " Tester.ipynb\t Trainer2.ipynb         Training_set\n",
            " Test_set\t'Trainer2(VGG).ipynb'   Validation_set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a88a3bbf51be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_data.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
          ]
        }
      ]
    }
  ]
}